# HTR transkribus / eScriptorium
## Transkribus
### écosystème
S'inscrit dans une ensemble de procédés
- traitement de l'image
- collecte de données
- annotation
- reconnaissance de texte + entrainement
- publication

Il existe plusieurs solutions pour utiliser Tanskribus
- Transkribus AI : par cliquer-déposer, directement dans le navigateur ;
- Transkribus lite : application en ligne aussi, accessible depuis n'importe quel pc ou tablette, contient la majorité des fonctionnalités proposées par Transkribus ;
- Transkribus expert-client : version complete, logiciel à installer sur son ordinateur. offre toutes les fonctionnalités de Transkribus ;
- Transkribus Metagrapho : API à installer sur serveur, pour créer ses propres flux de travail, permet d'intégrer Transkribus dans un système d'information déjà en place.

C'est 80 000 utilisateurs, 31M d'images, et 14 000 modèles HTR

Transkribus fonctionne également avec la scantent + application smartphone Docscan, pour traiter les documents directement au moment de la prise de vue. 
Trk propose également des solutions de publication. la plateforme est personnalisable et permet d'effectuer des recherches plein texte et par keyword spotting (données qui ont été écartées au moment de l'HTR)
Citizen & science, pour de la transcription participatve. En cours de développement dans le cadre d'un projet pilote de science citoyenne au Tyrol/autriche.

### utilisation
Trk propose des modèles publiques. Chaque utilisateur peut créer son propre modèle. Pour le moment 120 modèles publiques sont en ligne, pour des document du XI au XXIe siècle et dans 20 langues. 
Certains modèles atteignent 99,5% de reconnaissance de caractère. 
Quelques projets 
- Archives nationales de Berlin, 3,6M de fiches
- Zeitpunkt, 15M de pages de journaux, utilisation du modèle newsEye pour segmenter les articles
- Académie autrichienne des sciences, entraienement d'un modèle Fraktur pour la reconnaissance des caractère typographique, taux d'erreur inf à 1%
- Archives de la ville d'Amsterdam - VeleHanden : projet en collaboration avec TRK. gros succès, 4000 pages prévues mais 42 000 faites
- British Library également, pour des projet de langue indienne

### READ-COOP
coopérative à charte européenne, évolution d'un grand projet débuté en 2013, Transcriptorium, qui a évoluer en 2016 vers le consortium READ, qui a permis de développer la plateforme. En 2019 fin des subventions européennes, donc transformation vers une société coopérative européenne :
- appartient aux utilisateurs qui deviennent membres
- organisés de manière démocratique
- tous les fonds sont réinvestis dans la plateforme
- sert la communauté
- dirigée par un conseil d'administration élu 

### Cas pratiques : projet Nouvelle France numérique
Utilisation de Trk depuis 2017, quasiement depuis le début. L'objectif était de rassembler et transcrire l'ensemble des archives de la Nouvelle-France (16e-18e siècle). Grâce au HTR, le projet à pris un ampleur qui n'était pas envisagée au début (plutôt modeste), c'est aussi un projet participatif. 
Depuis le début c'est plus de 100 K pages qui ont été transcrite. Deux modèles sont publique pur le français entre le 16e et le 18e siècle, mais d'autres ne sont pas publiés. Ils peuvent toutefois être partagés, mais ils ne sont pas encore finalisés (+100). Beaucoup de types de document (archives judiciaire, correspondance, cahiers d'ordonnances, greffes de notaires, etc.)
très bonne intégration pour le travail en équipe, facilite le balisage des métadonnées (intégration XML), suivi des statut, etc. Outils de recherche très performant également (Solr), plein texte, Xpath ?, mais également keywork spotting. 
Documentation sur une chaîne youtube Youtube

### Q°
Pour ne pas faire un seul gros modèle générique ? ce n'est pas une question de performance mais de précision du modèle, si on a une seule main, avec un vocabulaire réduit, on préférera un modèle plus petit et propre, proposant de meilleurs résultats, à contrario, si on a plusieurs mains, etc. on se tournera vers un modèle plus généraliste.

## eScriptorium
C'est une autre système de HTR. Derrière il y a le logiciel Kraken, qui existe depuis quelques années, développé par Kiessling. Il permet la segmentation auto, la transcription auto, et optimisé pour les écritures historiques et non latines. Ce système est libre, gratuit et ouvert (le logiciel et les modèles).
Mais Kraken s'exécute en ligne de commande. 
eScriptorium est une interface web pour Kraken
- plus facile à utiliser pour les chercheur en SHS
- Il faut des bons algorithmes, mais aussi une bonne ingénierie.
- Ses début remonte à 2019, au sein du projet Scripta-PSL. Encore une fois, c'est libre, ouvert et gratuit.

### Le flux de travail
- importer les images
- segmentation, trouver les lignes de texte, mais également les régions (via kraken, via importation, à la main)
- transcrire le texte (via kraken, via importation, à la main)
    - corriger la transcription, (ré)entrainer le modèle, répéter
- exporter le texte et/ou les modèles
Bientôt il sera possible de modifier la séquence des ligne, via kraken (ou déjà possible, à la main), la corriger, (ré)entrainer le modèle
Concernant les modèles, bien évidemment, plus on a de documents et d'exemple, et plus on peut entrainer les modèles. 

En revanche même pour le travail à la main, l'interface est pratique et accessible (ligne par ligne) et permettant un suivi des modifications.

L'exportation des modèles fait partie de la documentation (q° de droit, sur les images qui ont permis l'entrainement, mais également le type d'écriture).

### développements en cours
- la balisage du texte (déjà en ß)
- l'annotation graphique (ß)
- la recherche de texte (ß)
- interface multilingue
- alignement automatiques des textes (alignement d'un texte préexistant avec l'image)

### les écritures rares
- différents types d'écriture, police, blocs Unicode
    - alphabets, logogrammes hiéroglyphes
    - pas de définition claire de signe et mot
- différentes directions
    - gauche-droite, droite-gauche, haut en bas, circulaire, etc.
    - écrire sur la ligne de base, sur la ligne supérieure ou verticale, dans la grille.
- un corpus souvent limité (trop petit pour Google)
    - il y a peut être peu d'exemples pour entrainer une machine
    - souvent pas de modèles préexistant
- Différentes conventions pour la transcirption et la présentation, même pour les langues « simples ».

Il faut donc de bons algorithmes, mais aussi une bonne ingénierie.

### types de projet eScriptorium / Kraken
- Usage personnel, sur un ordinateur (pas d'entrainement), ou avec gpu externe
- un seul projet (par ex. Viatnamica, EPHE) serveur + GPU modeste pour une dizaine d'utilisateurs
- consortium de taille moyenne (par ex FoNDUE en Suisse) cluster institutionnel
- consoritum de grande taille

### Exporter et échanger
On peut importer et exporter des transcriptions (ALTO, PAGE, conversion TEI (même si modèle de texte et pas de document), Open Web Annotation ?)
Les modèles sont publiés sur Zenodo.
Il y a également le projet HTR-United (pas propre à eScriptorium, mais pour tous les HTR).
SegmOnto vocabulaire pour décrire la segmentation d'une page.

Linteropérabilité est un réel défi (plus largement dans le cadre des dh), car chaque projet a ses propres objectifs, approches, c'est donc difficile de développer un modèle générique, applicable pour tout le monde et pour tous les projets.

## Table ronde

### les usagers
 les deux projets sont issus du monde universitaire, toutefois, ça interesse également les bibliothèques et centres d'archives notamment, car ça permettrait de proposer de nouveaux services aux usagers, (dématérialisation, recherche).
 Les généalogiste sont également intéressés bien évidemment, et également certains services administratifs, qui sont intéressés par la dématérialisation.

 Quelles limites pour les transcriptions, on réfléchie à la reconnaisance et la transcription de partitions de musiques, quid des formules mathématiques ou scientifiques ?
 Vraissemblablement sur les plateformes, impossible de ne serait-ce les transcrire via la plateforme ? voir projet d'édition des tables astrologiques de l'observatoire et un autre projet, qui utilise Transkribus, un peu eScriptorium, et un outils HTR d'IBM

 Q° du processus de contrôle et de correction ? Tout dépend de ce qu'on veut faire : données accès à des ressources ou les publier ? il n'est pas forcément nécessaire d'avoir des transcriptions parfaites. Mais dans l'absolu dès lors que la segmentation est correctement faite, il est possible de revenir sur ces transcriptions.

### moyens et ressources
Apparement, sur transkribus, il est possible de téléverser les images à océriser et de bénéficier de la puissance de calcule, est-ce disponible pour tout le monde ? 
Mettre en branle projet c'est finalement toujours le plus compliqué, c'est bien si on est au sein d'une équipe mixte ou d'un service (info et recherche), pour l'installation et la prise en main.

Concernant les modèles, eScriptorium est ouvert, des modèles sont accessibles et il est possible d'en partager, pour Transkribus, leur objectif est les données pas les modèles. 


## Projets utilisant Transkribus

### beaucoup de projet aux Pays-bas et en Belgique
Game of trones, etc.

### Between citizen science and handwriten text recognition - Vivien Popken
travail avec Trk depuis 4 ans. Le projet était de collecter les hanse records et de les rendre accessibles, puis de les traiter avec HTR pour finalement les publier.
Ils ont mis en place une école d'été. La citizen science est un moyent de faire participer le publique et de le former à de nouvelles pratiques, souvent issues du monde académique.
read.hanse.Sources!

### modèles généraux et abréviations - Tobias Hodel
Problèmes spécifiques ! entre 2016 et 2019, a suivi l'évolution du HTR, à travers une particupation à READ. 
Les modèles généraux : c'est pas seulement la reconnaissance d'une écriture spécifique, mais c'est aussi un type d'écriture.
Apprentissage à partir de documents d'une seule main. Dans ce temps il y a eu de grosse évolution dans les techniques de reconnaissance pour l'océrisation.
Le second défi est de connaitre l'efficacité d'un modèle, ils ont alors appliqué le premier modèle, mais le taux d'erreur n'était pas bon car l'entrainement avait été fait sur peu de documents et écrits par une seule main.
Avant de reprendre un modèle générique et de l'appliquer à un échantillon de test représentatif des documents à traiter.

Concernant les abréviations, il est possible de traiter pendant l'HTR.

### PENSE - Plateforme d'Édition Numérique de Source Enrichies - J.-C. Carius (INHA)
Le projet est développé sous forme AGILE, c'est à dire qu'il a été lancé très tôt, il est toujours en cours, mais déjà accessible à tous. 
Plusieurs projets participe de cette initiative.
Projet pilote : les papiers d'Antoine-Louis Barye, TRK n'a pas été utilisé pour la transcription, mais pour la segmentation, projet classique d'édition de documents.
Autres projets :
- correspondance de Doucet et René Jean ;
- les planches Karbowski.

Pour utiliser TRK, il fallait faire quelque part de la retro-ingénierie afin de rendre TRK utilisable aux chercheurs en histoire de l'art, qui ne sont pas nécessairement versés dans les nouvelles techno. Le tout a été de traduire le modèle de données de TRK pour ces chercheur afin qu'ils puissent traiter les métadonnées. 
L'API de TRK a aussi été utilisée pour développer une interface de suivie du travail. 

## eScriptorium
Exemples de projets utilisant eS. 

### Sofer mahier - Daniel Stökl Ben Ezra
Projet lancé avant même Transcriptorium, pour l'édition de 16 mss hébraïques en hébreux, très importants car le Talmud est un commentaire de ces textes.
L'objectif c'est la précision. Test du crowdsourcing, mais, malgré la transcription de plusieurs millier de lignes, la précision n'était pas satisfaisante. 
Finalement utilisation de Kraken, avec apprentissage d'un modèle, et utilisationd'édition vulgate pour apprendre au modèle. 
Il y a une hiérarchie de document (page, colonne ligne), mais our l'édition il fallait un hiérarchie, Livre, chapitre, etc. Donc apprentissage d'un modèle. 
Finalement modèle entrainé avec en 3% et 0.9% d'erreur !

### LectAuRep - Hugo Scheithauer
C'est une projet qui est finalisé aujourd'hui. Facilité la consultation des repertoires des notaires conservés au Minutier central.
Difficultés : beaucoup de mains présentes dans les répertoires (différences des graphies, différences dans les densités)
L'idée c'était de faire deux modèles génériques à partir d'une dizaine de mains pour obtenir un taux d'erreur inf. à 10%. Puis passer à des modèle plus poussé (pour un notaire qui a beaucoup produit par exemple) permettant de passer à un taux d'erreur de l'ordre de 5%.

Gros travail sur la segmentation, afin de rendre compte du tableau dans lesquels sont saisis les actes des notaires (à l'origine les transcriptions sortaient à plat, non structurées et impossible donc de rendre compte de ces tableaux).

### ANR e-Notre-Dame-Paris - Sergio Torres
Édition des registres du chapitre de Notre-Dame. 
L'idée c'est de développer un traitement HTR afin de traitement rapidement les 14 000 pages du corpus, avec si possible un taux d'erreur inf. à 10%.
Il y a un format pour les pages qui est à peu près suivi et le système comment à réussie à repérer ces zones : 
- Date
- conclusions
- titre (dans les marges)
- liste des chanoines
- numérotation

Ce qui est difficile dans le reconnaissance de texte du MA : les écriture (cursive, gothique, pré-gothique), les ligatures, chevauchements, concaténation, les pratiques d'écritures, abréviation, etc. la répartition du texte en colonne, en marginalia, etc.

Deux solutions interessantes mise en place par le projet
- capitalisation des entités nommées, le système arrive à mettre des capitales aux noms de lieux ou de personnes
- développement de certaines abréviation. 

Gagné 1% ou 2% d'erreur c'est très long et complexe, et il faut faire attention car le système peut tomber dans de l'hyper-correction.

## Présentation des plateformes

### Transkribus
Sur le site web on trouve à peu près tout ce que nous avons besoin, différente applications Transkribus en ligne (AI, Lite) et téléchargement de l'application bureau (expert-client), accès aux modèles publiques (principalement pour les manuscripts, mais aussi pour les imprimés), etc.
Informe aussi sur les coûts, tout est gratuit, sauf la reconnaissance de texte, quand on procède la reconnaissance de texte c'est payant, le reste est gratis (entrainement des modèles, etc.)
Trk AI : rapide, mais transcriptions, en fonction des cas très imparfaites.
Trk Lite : transcribus dans le navigateur, permet de faire la segmentation, apprentissage d'un modèle, transcription automatique, ajout des balises, possibilité de gérer des collections, vérifier le statut des actions lancées, gérer ses modèles, effectuer des recherches, etc.
Trk Expert-client : toutes les fonctionnalités avancées de Trk. vue sur son travail, gestion des collections, gestion du layout des documents, gestion des versions des documents (historique des modifications, qui a fait quoi et comment), possibilité de baliser le texte et des outils avancés (AI)
- détection automatique de la segmentation
- gestion des modèles (accès aux modèles publiques)
- calcule des taux d'erreur

### eScriptorium
msIA propose une instance eScriptorium (mais uniquement si on fait partie d'une institution membre)
Il est possible de récupérer Kraken d'avoir accès à des tutoriels, au code source de eScriptorium. 
eScriptorium fonctionne par projets, qui contiennent des documents, contenant eux mêmes des pages.
Pour un document ou une page, il possible de lancer un processus de segmentation automatique (ou le faire à la main), appliquer un modèle de transcription, etc.
La segmentation est vraiment efficace mais nécessite de la pratique. 
Dans le bloc ontology, il est possible de définir les types de régions, ou certains types de lignes, créer ses propre boutons pour l'annotation des textes.
Sur un point particulier, pour apprendre au modèle à reconnaitre des annotations marginales il faut entre 15 et 50 pages. idem pour les transcriptions. 
L'interface permet également la gestion de projets 
- données personnelles
- projets
- personnel (équipe)
- rapports divers (tâches, monitoring)
- metrics
- résumé du projet

Il propose également une fonctionnalité de recherche

L'interface propose 4 panels
- visualisation et annotation d'image
- segmentation
- transcription
- texte

Il y a aussi la gestion de claviers virtuels. 
Tout comme Transkribus, il est possible de gérer/rétablir l'ordre des lignes

#### Q°
La gestion des projets est très simple, chaque membre d'un équipe peut presque tout faire, ainsi l'annotation du texte par exemple n'est pas imputable à un membre en particulier. 
Le mode de publication des modèles est également léger (par de review avant publication, pas de validation), c'est un projet open-source, et ce serait contraire à cet esprit. Pour Trk il y a un validation lorsqu'un modèle est rendu public afin de vérifier que le modèle est suffisament documenté, pour les modèles privés, il n'y a pas de contrôle. 

## Workshop

### Transkribus
On téléverse ses documents sur les serveurs d'Insbrück. La collection est centrale, elle relie les documents aux utilisateurs et aux modèles. Les opérations ne se font donc pas sur notre machine. Cela permet un travail en équipe avec gestion des rôles/droits utilisateurs.

Verser un document : 
- Il est possible de travailler un peu en local, pour transcrire (icone open local document), mais pas accès la segmentation ;
- import document (si éditeur ou propriétaire) permet de téléverser un document ;
    - soit .pdf, soit un dossier comportant des images, 
    - une fois téléversé, transcribus décompose le .pdf en images individuelles et ajoute un fichier doc.xml et un dossier pages contenant d'autre document.xml pour chaque images (transcription + coordonnées),
    - possibilité également de téléverser via FTP pour gagner du temps.

Exporter les documents : 
    - Document transkribus brut au format Mets (dossier avec nom du document contenant les images, et les documents xml associés)
    - mais propriétés d'export et formats personnalisables : pdf, pdf avec page titre contenant les métadonées, TEI, TEI avec XSL perso, .docx, filename patern, etc.

5 onglets de navigation principaux : Server, Tools, Layout, Overview, Metadata :

Overview : vue générale sur le document (miniatures, nom du doc, etc.) 

Serveur :
- document management : permet de visualiser les documents rapidement ; 
- Jobs : permet de voir les tâches en cours de traitement (transcription, segmentation) ;
- collections : permet de choisir un collection mais également de gérer ses crédits, gérer les utilisateurs et leur rôle pour le partage des collections ;
- recherche : 
    - recherche du texte dans les métadonnées, 
    - fulltext (solr), avec des options intéressante, notamment le mode fuzzy (permet un certain taux de caractères aléatoires),
    - keyword spotting : compare avec les mots qui n'ont pas été retenues lors de l'HTR, avec un seuil d'erreur. Ça devient très puissant puisqu'avec cet outil, on ne cherche plus nécessaire la perfection de la transcription, la donnée n'est pas parfaite, mais elle devient accessible,
    - par balises et attributs, permet par exemple de selectionner ces balises en fonction d'un critère de recherche et de mettre à jour leurs attributs par lot.
        - si on a un peu de bruit dans la liste des résultats, on met à jour la première occurence des balises recherchées, puis on sélectionne toutes les autres occurences pertinentes et on clique sur update.  

Tools : 
- permet de configurer la segmentation (selection du preset, mais aussi quelles pages sont concernées, filtres, etc.) ;
- configuration de la reconnaissance de texte (text recognition) ;
    - choix entre HTR ou textes imprimés,
    - Il est possible ensuite d'appliquer la reconnaissance de texte ou d'entrainer un modèle :
        - Modèles (models) : liste de tous les modèle disponibles, avec leurs propriétés. Un clique droit sur un modèle, permet de la partager dans une autre collection par exemple
        - reconnaissance de texte (run) :
            - possibilité de lancer la reconnaissance sur une page, sur une selection de pages, ou tout le document,
            - si on applique la reconnaissance, il faut alors choisir un modèle à appliquer, et surtout appliquer la fonction keyword spotting (très utile pour les grands documents) ;
            - NB, pour les chiffres c'est un problème, puisque qu'il n'y a pas le logique d'occurence, il n'y a pas plus de chance de trouver 1 ou 2 ou 1350, alors que pour les mots, on a des lexiques. Une fois fait on peut passer le statut en « done ». dans la barre supérieure ;
        - entrainement d'un modèle (train)
            - lorsque l'on veut entrainer un modèle c'est mieux de travailler dans une collection, dans laquelle on peut inclure des documents de plusieurs collections. C'est l'usage qui force l'apprentissage sur modèle : si on rétablie les accents, la séparation des mots agglutinés, le rétablissement des majuscules… alors l'algorythme aura tendance à rétablir aussi, ce sont des choix à faire dès le début. Plus on respecte le texte et plus on a un modèle précis et efficace,
            - si création :
                - nom de modèle,
                - langue (code langue ISO),
                - deux algo :
                    - PyLaia (segmente au mot et plus de réglages possible),
                    - HTR CITilab :
                        - possibilité d'ajouter des balises à prendre en compte (abréviation, noms de personnes, noms de lieux), ainsi que les attribut
                        - ne pas oublier d'omettre les balises gap et unclear
                - nb d'époch : moins on met de cycle de validation, plus c'est rapide, mais plus on en fait de cycle et plus on augmente la précision)
                - en générale on utilise 10% pour la validation,
            - possibilité, un peu sur le même principe, de ré-entrainer un modèle existant pour l'améliorer :
- apprentisage de l'analyse spatiale (P2PaLA), pour la reconnaissance des divisions du texte.
- calcules des performances d'un modèle (quand on le corrige).


Metadata : 
- document, permet de renseigner les métadonnées, aisni que les conventions éditoriales ;
- commentaires ;
- permet de baliser le document ;
    - sous onglet textual pour le texte : noms de personnes, de lieux, dates, abréviations, lacunes, glyphs, etc. et possibilité d'ajouter des attributs,
    - sous onglet structural pour la division du texte : div, p, header, etc. (possibilité de selectionner les régions avec des règles directement sur l'image),
    - pour les formules mathématiques, assez limité pour le moment, utilisation du clavier virtuel, avec ajout de caractères custom


Layout
- une fois la segmentation faite, et une page selectionnée, cet onglet permet de modifier la segmentation si elle présente des erreurs.

Dans le menu principale (hamburger) on peut synchronier des documents avec des transcriptions (sous-menu documents -> sync local transcriptions with docs (si transcriptions issues de Transkribus), ou sync local text files with doc (transcriptions au format .txt, idéalement avec les retours à la ligne, mais pas obligatoire, dans ce dernier cas, on peut entrainer un modèle, à la première passe il va associer mettons 1 ligne sur 10, puis on le ré-entraine, et à la 3e passe tout sera associé, à partir d'un texte brut, sans retour à la ligne)). 

NB 1 : Seule l'océrisation est payante. Pour gérer ses crédits => onglet server => collection => credit manager.
NB 2 : Quand on fait une tâche à la main, ne pas oublier de passer le statut sur « done » quand il est achevé.
NB 3 : il est possible d'appliquer deux modèles sur une même page pour le HTR (imaginons un doc bilingue ou contenant deux alphabets, il faut faire une première segmentation, puis appliquer le HTR, puis compléter la segmentation et cocher find nex text region lors de la seconde application du HTR) mais ce n'est pas très efficace, il est préférable d'entrainer un seul modèle.

### eScriptorium
eScriptorium nécessite d'avoir accès à une instance (en local ou sur un serveur) et s'exécute dans un navigateur.
accès à l'[instance msIA](https://msia.escriptorium.fr/projects/)

Pour créer un projet, il suffit de lui donner un nom.

Plusieurs onglets lors de la création d'un document:

- Description :
    - nom du document
    - type de caractère (latin pour français)
    - sens de lecture
    - ligne de base pour la reconnaissance des caractère occidentaux (topline pour sanscri et ligne centrale pour le chinois)

- Ontology : permet d'ajouter des types de région et types de ligne, qui seront utilisés pour attribuer des régions lors de la segmentation. Voir segmOnto

- Images : 
    - permet de charger images
    - segment permet de faire une segmentation automatique en appliquant un modèle eventuellement avec détection de ligne mais aussi des région
    - transcribe permet de lancer une transcription automatique sur la ou les images sélectionnées
        - NB pour accéder à la transcription automatique, penser, une fois dans l'édition de l'image, à changer la version (manual par défaut) 
        - NB 2 attention, si on applique une transcription automatique avec un modèle spécifique pour une seule page par exemple, la version apparait pour toutes les pages de la collection, même si elle est vide pour une page en cours. De fait, faire attention lorsqu'on supprimer une version, car ça supprime toutes les pages (même celle pour laquelle on a souhaité appliqué ce modèle pour la transcription)
    - train (si on a les droits) pour (ré)entrainer un modèle sur toutes les images ou sélection d'images
    - export, pour exporter les transcriptions (format text, PAGE et ALTO) avec des filtres de ce que l'on souhaite dans la transcription (types de régions, type de lignes)
    - import permet d'importer les images, mais aussi des transcriptions (au format ALTO ou PAGE, il lui faut les coordonées des lignes et zones le cas échéant)


- Edit : pour la segmentation et la transcription.
    - on clique ensuite sur l'onglet transcription sur les segments pour transcrire ligne à ligne avec le facsimilé de la ligne juste au dessus
    - les vues
        - doc 
        - segmentation 
            - on détermine les lignes (lorsque l'on trace les lignes de base la première fois pour une image, il faut penser à cliquer sur le pouce jaune pour lancer la segmentation)
            - on peut déterminer des régions (penser à cliquer sur switch mode region)
            - lorsque l'on sélectionne une ligne ou une région, il est possible de la relier à l'ontologie
        - transcription
        - texte permet notamment d'inverser l'ordre des lignes


NB : ordre d'idée, suite question à Alix Chagué et Sébastien Cretin (BnF), ce dernier à eu un expérience avec un manuscrit de Victor Hugo ? sur lequel ils ont fait des test : il faut environ une 60aine de pages transcrites, ensuite on arrive à un plateau et il devient alors difficile d'améliorer les choses, c'est même parfois contre productif car quand le modèle est trop entrainé, ça peut ralentir le process.





